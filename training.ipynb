{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from DataAugmentation import DatasetAugmentation\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms.v2 as v2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.tv_tensors import BoundingBoxFormat, BoundingBoxes\n",
    "from ultralytics.utils.loss import v8DetectionLoss\n",
    "from torchvision.transforms.v2 import ConvertBoundingBoxFormat\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to debug the dataset structure \n",
    "# Evaluation dataset\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = 640\n",
    "\n",
    "resize_transform = v2.Compose([\n",
    "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    v2.SanitizeBoundingBoxes(),\n",
    "    v2.ToImage(),\n",
    "])\n",
    "\n",
    "val_dataset = DatasetAugmentation(\n",
    "    training_path=\"augmented_data/val\",\n",
    "    split_images=False,\n",
    "    perform_transformations=True\n",
    ")\n",
    "val_dataset.transforms = resize_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the validation dataset: <class 'int'>\n",
      "Dimnension of the images in the validation dataset: <class 'torchvision.tv_tensors._image.Image'>\n",
      "Number of classes in the validation dataset: tensor([[362.1333, 360.4000,  58.6667,  87.2000]])\n",
      "Number of bounding boxes in the validation dataset: tensor([3])\n",
      "Image 1:\n",
      "boxes = BoundingBoxes([[356.5333, 360.8000,  51.7333,  59.2000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 2:\n",
      "boxes = BoundingBoxes([[181.5861, 219.8304,  49.5723,  65.1536],\n",
      "               [514.1365, 274.9248,  49.7835,  61.2096],\n",
      "               [441.1200,  82.9248,  37.0848,  74.0096],\n",
      "               [360.3563, 333.7264,  47.8592,  62.6528],\n",
      "               [193.1968, 439.6192,  42.2165,  70.0640],\n",
      "               [439.1691, 512.8960,  41.7163,  73.6864]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 3:\n",
      "boxes = BoundingBoxes([[ 75.4667, 152.4000,  57.0667,  87.2000],\n",
      "               [514.1334, 424.4000,  55.4667,  80.8000],\n",
      "               [376.8000, 529.2000,  45.3333, 136.8000],\n",
      "               [311.7333, 233.6000,  47.4667,  64.0000],\n",
      "               [236.2667, 557.6000,  45.8667,  56.0000],\n",
      "               [516.2667, 578.8000,  57.6000,  95.2000],\n",
      "               [403.4667, 359.2000,  43.2000,  72.0000],\n",
      "               [546.1334, 264.0000,  51.2000,  80.0000],\n",
      "               [400.8000, 172.8000,  59.2000,  89.6000],\n",
      "               [536.0000, 142.0000,  58.6667,  85.6000],\n",
      "               [250.9333, 308.4000,  66.6667,  95.2000],\n",
      "               [130.9333, 486.0000,  61.3333,  85.6000],\n",
      "               [271.4667, 115.2000,  58.6667,  92.8000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 4:\n",
      "boxes = BoundingBoxes([[155.4848, 209.1360,  56.7467,  84.2976],\n",
      "               [165.3685, 281.1456,  56.6048,  83.2496],\n",
      "               [282.4715, 283.2736,  88.4981,  73.8528],\n",
      "               [374.0800, 310.5808,  59.4485,  88.7888],\n",
      "               [580.6581, 513.0048,  50.2048,  59.5024]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 5:\n",
      "boxes = BoundingBoxes([[293.9008, 280.0736,  58.0245,  87.5072],\n",
      "               [350.5728, 290.0480,  56.5227,  87.1904],\n",
      "               [317.2118,  89.1952,  59.8443,  90.2832],\n",
      "               [161.6405, 451.3808,  61.5915,  93.0544],\n",
      "               [505.8677, 460.0464,  60.2699,  89.0544]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 6:\n",
      "boxes = BoundingBoxes([[310.6155, 256.7264,  59.0379,  89.4144],\n",
      "               [199.5829, 472.6976,  61.3589,  90.0368],\n",
      "               [393.9051, 553.9392,  51.8965,  78.5136],\n",
      "               [429.7760, 297.9344,  53.8645,  78.2480],\n",
      "               [520.0438, 344.5904,  55.0464,  77.1744]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 7:\n",
      "boxes = BoundingBoxes([[448.0000, 167.2000,  55.4667,  84.8000],\n",
      "               [367.2000, 106.4000,  60.2667,  91.2000],\n",
      "               [294.6667, 143.2000,  53.8667,  78.4000],\n",
      "               [244.5333, 217.6000,  47.4667,  64.0000],\n",
      "               [236.5333, 320.8000,  63.4667,  97.6000],\n",
      "               [244.2667, 421.6000,  40.5333,  72.0000],\n",
      "               [289.8667, 490.4000,  52.8000,  88.0000],\n",
      "               [373.3333, 529.2000,  59.7333,  92.0000],\n",
      "               [428.8000, 452.8000,  38.4000, 131.2000],\n",
      "               [473.0667, 415.2000,  56.5333,  81.6000],\n",
      "               [476.5334, 257.6000,  61.3333,  89.6000],\n",
      "               [480.0000, 344.0000,  42.6667,  70.4000],\n",
      "               [360.5334, 333.6000,  72.5333,  97.6000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 8:\n",
      "boxes = BoundingBoxes([[139.9253, 469.8144,  61.3963,  93.4224],\n",
      "               [244.8203, 559.1920,  60.4139,  92.9744],\n",
      "               [392.5579, 388.8240,  49.5424,  83.7600],\n",
      "               [449.9947, 285.3360,  55.1893,  88.6240],\n",
      "               [381.9467, 221.0080,  56.0533,  86.6880],\n",
      "               [594.4758, 332.2448,  58.6293,  85.1616],\n",
      "               [562.3552, 516.2928,  58.3989,  85.8112],\n",
      "               [526.2037, 418.8128,  54.7189,  78.0512]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 9:\n",
      "boxes = BoundingBoxes([[324.0043, 262.0448,  52.0981,  78.6480],\n",
      "               [490.8512, 381.8848,  56.9024,  85.2624],\n",
      "               [458.8832, 469.0064,  53.0549,  78.7072],\n",
      "               [573.8593, 455.5936,  62.5621,  95.0784],\n",
      "               [230.9579, 436.1008,  58.3595,  87.5616]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 10:\n",
      "boxes = BoundingBoxes([[291.2245, 205.3696,  56.9845,  86.9888],\n",
      "               [284.6859, 335.8320,  59.1627,  89.3328],\n",
      "               [377.9979, 273.2032,  60.3328,  89.9744],\n",
      "               [358.2325, 401.3488,  53.0795,  78.9296]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 11:\n",
      "boxes = BoundingBoxes([[289.2267, 390.7392,  37.2981,  76.8400],\n",
      "               [237.6352, 382.2608,  60.6933,  90.8128],\n",
      "               [107.2181, 229.4352,  64.3915,  95.5616],\n",
      "               [150.5952, 561.5136,  39.8581,  73.8528],\n",
      "               [265.3867, 507.9632,  50.7019,  54.7536],\n",
      "               [341.0848, 537.8624,  61.0133,  91.0848],\n",
      "               [360.4267, 208.3648,  35.6981,  74.7568]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 12:\n",
      "boxes = BoundingBoxes([[388.0000, 259.2000,  50.6667,  67.2000],\n",
      "               [199.2000, 364.0000,  48.5333,  59.2000],\n",
      "               [268.0000, 174.4000,  64.5333,  86.4000],\n",
      "               [300.5334, 558.8000,  52.8000,  87.2000],\n",
      "               [378.9333, 366.0000,  58.1333,  85.6000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 13:\n",
      "boxes = BoundingBoxes([[263.0197,  59.5664,  63.0389,  94.5584],\n",
      "               [470.3190, 350.2128,  60.2677,  89.9600],\n",
      "               [280.5611, 526.7472,  55.0379,  65.5312],\n",
      "               [148.5536, 605.6656,  55.5285,  64.3840],\n",
      "               [392.4768, 159.3360,  57.7696,  87.3616]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 14:\n",
      "boxes = BoundingBoxes([[168.1867, 196.9696,  48.8779,  61.3296],\n",
      "               [204.1824, 398.6992,  44.9333,  70.8688],\n",
      "               [ 78.1376, 332.7872,  69.0517,  99.6128],\n",
      "               [222.1888, 491.8704,  63.1051,  98.6224],\n",
      "               [346.5803, 409.1072,  89.8667,  67.8960],\n",
      "               [323.2885, 550.1024,  61.7835,  89.2064],\n",
      "               [299.6384, 236.7072,  58.9845,  89.6448],\n",
      "               [240.8480, 110.5696,  40.9835, 138.8736]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 15:\n",
      "boxes = BoundingBoxes([[406.1621, 187.8160,  41.4656, 144.5424],\n",
      "               [395.8688, 422.5936,  42.9707, 143.5632],\n",
      "               [155.9061, 496.0352,  56.8992,  84.5888],\n",
      "               [121.7845, 358.7696,  43.1392,  79.9392],\n",
      "               [135.5072, 221.1472,  42.0917,  79.6256],\n",
      "               [156.7584, 118.3776,  55.8347,  84.0608]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 16:\n",
      "boxes = BoundingBoxes([[288.6752, 348.8224,  52.1952,  78.3376],\n",
      "               [337.9915, 370.5312,  51.9819,  78.0240],\n",
      "               [162.5952, 297.7024,  41.1019,  74.7648],\n",
      "               [105.2267, 276.2608,  66.8085,  95.8816],\n",
      "               [446.2752, 383.6640,  48.1067,  52.5552],\n",
      "               [427.9115, 482.9312,  47.2885,  68.6896]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 17:\n",
      "boxes = BoundingBoxes([[230.1333, 190.8000,  67.7333, 112.8000],\n",
      "               [307.7333, 438.8000,  75.7333, 106.4000],\n",
      "               [388.2667, 207.2000,  57.6000,  88.0000],\n",
      "               [396.0000, 316.8000,  58.1333,  83.2000],\n",
      "               [310.1333, 214.4000,  67.7333, 102.4000],\n",
      "               [307.7333, 328.0000,  71.4667,  99.2000],\n",
      "               [221.0667, 421.2000,  68.8000, 106.4000],\n",
      "               [147.2000, 194.0000,  61.8667,  93.6000],\n",
      "               [148.5333, 302.8000,  60.2667,  87.2000],\n",
      "               [226.6667, 303.2000,  56.5333,  91.2000],\n",
      "               [396.2667, 433.2000,  56.5333,  92.0000],\n",
      "               [148.0000, 421.6000,  57.0667,  84.8000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 18:\n",
      "boxes = BoundingBoxes([[296.7285, 444.0736,  61.5467,  92.8416],\n",
      "               [216.4267, 369.4576,  61.2981,  91.3424],\n",
      "               [132.1419, 354.9792,  70.1515, 101.3200],\n",
      "               [182.5419, 483.9152,  69.9733,  98.3888],\n",
      "               [333.9382, 224.3120,  62.7200,  94.3856],\n",
      "               [417.7248, 296.8208,  67.0933,  99.6704],\n",
      "               [428.9781, 139.0608,  66.1333, 100.9472],\n",
      "               [355.9467,  62.7392,  59.0933,  90.1712]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 19:\n",
      "boxes = BoundingBoxes([[343.6427, 330.5344,  70.7520,  94.1184]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 20:\n",
      "boxes = BoundingBoxes([[391.4667, 372.8000,  53.3333,  86.4000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 21:\n",
      "boxes = BoundingBoxes([[412.6758, 580.3077, 184.6800, 119.3846]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 22:\n",
      "boxes = BoundingBoxes([[223.5930, 265.5140,  69.2702,  62.4143]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 23:\n",
      "boxes = BoundingBoxes([[ 84.8828, 512.1197,  96.3530,  96.1637],\n",
      "               [311.7772,  55.1448,  92.1275,  94.9597],\n",
      "               [ 83.8108,  93.4718,  60.9991,  68.0822],\n",
      "               [299.4073, 298.6773,  92.7496,  92.7453],\n",
      "               [332.0571, 579.4425,  98.0650,  87.4669],\n",
      "               [535.5994, 253.8720, 101.7928,  88.1325]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 24:\n",
      "boxes = BoundingBoxes([[283.1917,   1.1788,  75.3685,   2.3577],\n",
      "               [426.1263,  54.4412, 163.6628, 108.8823],\n",
      "               [202.1521, 279.4056,  97.4535, 110.2068],\n",
      "               [564.3995, 274.1360,  88.7186, 104.0151],\n",
      "               [246.3431,  65.6101, 101.5219, 106.1307],\n",
      "               [133.5741,  53.2284,  74.6222,  33.9137],\n",
      "               [ 74.5943, 149.2963, 130.6654, 141.5948],\n",
      "               [ 29.8490, 104.9469,  59.6981,  36.2878],\n",
      "               [320.2852, 354.1079, 141.8281, 157.0369],\n",
      "               [578.5403, 488.4689, 122.9194, 142.8861],\n",
      "               [123.7399, 400.0724, 133.2261, 142.0179]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 25:\n",
      "boxes = BoundingBoxes([[436.5066, 302.6194, 191.4960, 225.5454],\n",
      "               [469.8601, 110.6612, 191.0173, 221.3223]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 26:\n",
      "boxes = BoundingBoxes([[615.2524,  84.0242,  49.4951, 150.7180],\n",
      "               [155.7066, 377.8849, 206.2859, 153.9402]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 27:\n",
      "boxes = BoundingBoxes([[240.6245, 404.4031, 110.7288, 127.4420],\n",
      "               [465.7491, 200.5603, 114.0609, 129.1122],\n",
      "               [233.8557,  41.5285,  97.3048,  83.0570],\n",
      "               [ 95.3855, 307.9723,  99.8500, 112.4284],\n",
      "               [ 21.1669, 226.3766,  40.3472,  93.1127]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 28:\n",
      "boxes = BoundingBoxes([[621.6224, 413.1158,  36.7551, 113.7039],\n",
      "               [566.4345, 549.9630,  46.7654, 101.6291],\n",
      "               [303.9378, 552.2927, 218.6100, 175.4146],\n",
      "               [141.7806, 469.7786, 155.8120, 131.9786],\n",
      "               [ 81.3706, 330.7076, 162.7411, 167.4564],\n",
      "               [101.9823, 156.3962, 149.1606, 157.4718],\n",
      "               [249.7171,  97.5711, 253.1382, 173.5913],\n",
      "               [350.4452,  63.9116, 184.3966, 127.8232],\n",
      "               [578.2501, 165.0380, 123.4997, 170.7022],\n",
      "               [475.7464,  86.3570, 153.5945, 131.7514],\n",
      "               [390.1469, 318.2603, 226.4814, 212.0875]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 29:\n",
      "boxes = BoundingBoxes([[615.7924, 466.4409,  48.4153, 102.6056],\n",
      "               [490.9334, 564.6041,  81.9541, 102.1136],\n",
      "               [290.5206, 377.4893,  67.2065,  91.9934],\n",
      "               [212.6050, 263.8286,  74.8669,  97.3355],\n",
      "               [304.9152, 193.1774,  76.0389,  95.2092],\n",
      "               [ 60.1828, 517.4880,  79.2208,  94.2462],\n",
      "               [109.2239, 410.4259,  74.2287,  85.7235]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 30:\n",
      "boxes = BoundingBoxes([[380.8905,   2.1843,  95.7176,   4.3064],\n",
      "               [234.2628, 324.7067, 104.0753, 129.9218],\n",
      "               [128.4224, 251.5988,  96.0766, 121.1348],\n",
      "               [144.1012, 513.6420, 116.0521, 142.8484]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 31:\n",
      "boxes = BoundingBoxes([[367.6469, 221.9217,  99.5363,  97.4938],\n",
      "               [356.2256, 368.1389, 103.3409, 100.1208],\n",
      "               [519.2161, 297.9470, 105.3848, 100.8399],\n",
      "               [484.6914, 441.5677,  92.7152,  88.4613]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 32:\n",
      "boxes = BoundingBoxes([[399.5501, 464.9299, 113.7039, 108.7829],\n",
      "               [462.2141, 525.7451, 151.9175, 150.2800],\n",
      "               [624.0871, 461.2685,  31.8258,  74.6536],\n",
      "               [202.4883, 512.0767, 152.5184, 150.9108],\n",
      "               [500.8055, 229.3872, 109.9998, 105.0641]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 33:\n",
      "boxes = BoundingBoxes([[512.9083, 406.8171,  92.2248, 130.2864],\n",
      "               [603.2037,  98.9798,  71.9655, 165.6748],\n",
      "               [103.8341, 185.2444, 119.4768, 135.9103],\n",
      "               [367.4182, 384.4584, 117.3799, 149.5548]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 34:\n",
      "boxes = BoundingBoxes([[424.7186, 597.5809,  92.2746,  84.8382],\n",
      "               [121.2799, 293.8279,  88.2182,  96.6013],\n",
      "               [399.0421, 104.2607,  80.5629,  70.3691],\n",
      "               [592.2709,  27.0424,  81.2811,  54.0847],\n",
      "               [235.2230, 498.7962,  84.5615,  93.8111]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 35:\n",
      "boxes = BoundingBoxes([[437.2414,  65.1211,  83.3244, 100.0788],\n",
      "               [167.0109, 133.8022,  95.9288,  92.2969],\n",
      "               [ 55.1140, 168.5140, 107.6045, 129.2098],\n",
      "               [148.7366, 421.5204,  93.3480, 183.0921],\n",
      "               [ 10.9067, 372.2987,  21.8133, 125.2575],\n",
      "               [380.1768, 330.1097, 121.4104, 121.0904]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 36:\n",
      "boxes = BoundingBoxes([[631.8453, 198.9341,  16.3095, 207.0808],\n",
      "               [622.4205, 535.2917,  35.1590, 205.6779],\n",
      "               [232.0128, 609.9576,  97.0976,  60.0848],\n",
      "               [173.7848, 443.8533,  73.6164, 114.5261],\n",
      "               [197.2023, 246.6865,  71.8289, 114.0768],\n",
      "               [233.4671,  99.4521,  95.2810, 120.4309]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 37:\n",
      "boxes = BoundingBoxes([[ 25.3675, 444.9673,  45.8785, 113.0678],\n",
      "               [ 38.0813, 476.3005,  45.6949, 112.6152],\n",
      "               [  8.6610, 371.1839,  17.3220, 107.9110],\n",
      "               [  5.4741, 340.2363,  10.9482, 138.3897],\n",
      "               [242.3215, 415.5035, 163.7119, 129.7941],\n",
      "               [249.7132, 571.6440, 170.9003, 136.7120]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 38:\n",
      "boxes = BoundingBoxes([[311.6430, 133.3250, 103.0426, 140.6046],\n",
      "               [429.6957, 442.4556, 115.2130, 132.6270],\n",
      "               [552.2109, 153.7675,  87.6268, 109.6915],\n",
      "               [563.9756, 290.3833,  88.4381, 103.7083],\n",
      "               [433.3468, 162.7423, 103.0426, 127.6410],\n",
      "               [429.6957, 304.3440, 108.7221, 123.6522],\n",
      "               [297.8499, 420.5173, 104.6653, 132.6270],\n",
      "               [185.4767, 137.3138,  94.1176, 116.6719],\n",
      "               [187.5051, 272.9324,  91.6836, 108.6943],\n",
      "               [306.3691, 273.4310,  86.0041, 113.6803],\n",
      "               [564.3813, 435.4752,  86.0041, 114.6775],\n",
      "               [186.6937, 421.0159,  86.8154, 105.7027]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 39:\n",
      "boxes = BoundingBoxes([[482.5525, 502.2813, 154.4033, 188.1409],\n",
      "               [270.2482, 472.4597, 176.7039, 208.6921],\n",
      "               [397.2003, 638.3530, 176.2552,   3.2939]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 40:\n",
      "boxes = BoundingBoxes([[509.9822, 322.0094, 189.8373, 190.2519]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 41:\n",
      "boxes = BoundingBoxes([[209.9602, 431.3026, 140.6593, 134.9412]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 42:\n",
      "boxes = BoundingBoxes([[369.9462, 323.9556, 126.3007, 148.6786]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 43:\n",
      "boxes = BoundingBoxes([[ 76.7665,  92.5149, 116.1677, 117.2277]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 44:\n",
      "boxes = BoundingBoxes([[181.4936, 432.0422, 103.8865,  86.2698],\n",
      "               [337.3463, 636.7360,  75.1939,   6.5280],\n",
      "               [489.4969, 340.8781, 100.0693,  88.0615],\n",
      "               [635.3092, 192.5161,   3.6464,  94.2918],\n",
      "               [320.7514, 105.9174,  88.2177, 102.4300]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 45:\n",
      "boxes = BoundingBoxes([[629.7297, 536.8889,  20.5405,  99.3732],\n",
      "               [158.6486, 107.4872,  76.5766, 155.8974],\n",
      "               [268.5586, 444.3533,  80.1802,  72.9345],\n",
      "               [396.0360,  75.1225,  77.4775,  63.8177],\n",
      "               [113.6036, 301.2194,  72.9730,  82.0513],\n",
      "               [118.1081, 513.6410, 100.0000, 102.1083],\n",
      "               [371.2612, 359.1111, 112.6126, 108.4900],\n",
      "               [573.9639, 156.7180, 103.6036,  97.5499],\n",
      "               [336.5766, 579.2820,  99.0991, 105.7550]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 46:\n",
      "boxes = BoundingBoxes([[549.4040, 403.5405, 147.6371, 132.1262],\n",
      "               [ 49.3596, 102.3143,  98.7192,  88.5453]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 47:\n",
      "boxes = BoundingBoxes([[328.1634, 205.0844, 157.6171, 156.1865],\n",
      "               [424.2108, 143.1274, 155.0315, 153.9930],\n",
      "               [234.5614,  37.5451, 129.7409,  75.0902],\n",
      "               [253.2365, 534.3699, 167.4350, 165.9471],\n",
      "               [629.9136, 224.1742,  20.1728,  84.5262]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 48:\n",
      "boxes = BoundingBoxes([[138.4115, 256.3980, 118.0364, 103.9400],\n",
      "               [376.6531, 304.3004, 107.6932,  90.9596],\n",
      "               [557.1285, 358.5358, 110.0561,  89.7116]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 49:\n",
      "boxes = BoundingBoxes([[478.8956,  55.6052, 122.8645, 107.9713],\n",
      "               [499.6031, 229.7090, 164.2795, 164.6563],\n",
      "               [479.5858, 399.7638, 104.9180, 121.4677],\n",
      "               [361.5530, 515.8329, 136.6695, 148.4606],\n",
      "               [178.6367, 251.3032, 187.7480, 164.6563]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 50:\n",
      "boxes = BoundingBoxes([[506.6479, 391.9308, 137.8731, 131.5947],\n",
      "               [346.8051, 229.3417, 153.5881, 139.2365],\n",
      "               [536.1781, 128.2765, 155.9926, 136.1948],\n",
      "               [ 13.1525, 303.0397,  26.3050, 133.7967],\n",
      "               [ 57.6868, 582.3937, 115.3736, 115.2125],\n",
      "               [134.7206, 439.0461, 152.2790, 122.6256]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 51:\n",
      "boxes = BoundingBoxes([], size=(0, 4), format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 52:\n",
      "boxes = BoundingBoxes([[154.5556,  74.2467, 135.4088, 129.9795],\n",
      "               [170.0930, 269.1849, 140.5845, 133.4820],\n",
      "               [ 10.0220, 175.6043,  20.0441, 134.4407]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 53:\n",
      "boxes = BoundingBoxes([[538.8762, 446.2964,  72.6823, 120.6753],\n",
      "               [438.3407, 432.9812, 118.2722, 142.6192],\n",
      "               [184.1990, 192.9724, 125.4786, 150.0771],\n",
      "               [492.4196, 613.6996,  98.8020,  52.6009]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 54:\n",
      "boxes = BoundingBoxes([[583.2857, 331.2302, 113.4286,  99.2981]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 55:\n",
      "boxes = BoundingBoxes([[ 96.7591, 154.8608, 193.5182, 263.6731],\n",
      "               [  8.5446, 604.9177,   2.3882,  70.1647]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 56:\n",
      "boxes = BoundingBoxes([[512.8567, 624.5002,  42.9593,  30.9995],\n",
      "               [594.0222, 414.7184,  91.9555, 104.0159],\n",
      "               [588.7824, 499.8947,  51.5776, 108.4073],\n",
      "               [596.5092, 302.7027,  86.9817, 147.3173],\n",
      "               [412.0484, 313.9496, 154.8457, 130.8362],\n",
      "               [516.0745, 175.2657, 128.4767, 136.2325],\n",
      "               [385.3033, 531.3158, 124.9759, 134.9360],\n",
      "               [415.1482, 628.6456,  92.7793,  22.7087]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 57:\n",
      "boxes = BoundingBoxes([[494.8060, 477.2315, 166.8234,  64.9766],\n",
      "               [230.8837, 445.3238, 165.8553,  66.8412],\n",
      "               [169.8085, 129.8321, 100.5893,  80.1372],\n",
      "               [327.7563,  96.6881,  94.0954,  62.0115],\n",
      "               [481.7651, 125.3141,  93.6465,  60.6349],\n",
      "               [592.9121, 160.8908,  94.1758,  78.7216]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 58:\n",
      "boxes = BoundingBoxes([[227.7496, 361.1642,  95.9659, 105.8657],\n",
      "               [147.9137, 395.7654,  95.5744, 105.4412],\n",
      "               [432.3508, 278.1826,  77.0501,  99.7216],\n",
      "               [525.6537, 242.6996, 122.3371, 130.0164],\n",
      "               [  8.5195, 424.9424,   6.6028,  65.7938],\n",
      "               [ 34.7375, 547.7474,  38.3901,  88.6860]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 59:\n",
      "boxes = BoundingBoxes([[371.0296, 537.7448, 120.2367, 145.7835],\n",
      "               [508.7811, 217.2278, 134.4379, 137.5121],\n",
      "               [620.3077, 516.5493,  39.3846, 113.7318],\n",
      "               [513.0414, 507.2439, 120.2367, 132.3425],\n",
      "               [508.7811, 360.4265, 126.8639, 128.2068],\n",
      "               [354.9349, 239.9741, 122.1302, 137.5121],\n",
      "               [223.8107, 533.6091, 109.8225, 120.9693],\n",
      "               [226.1775, 392.9951, 106.9823, 112.6979],\n",
      "               [364.8757, 392.4782, 100.3550, 117.8675],\n",
      "               [627.8817, 224.4652,  24.2367, 118.9015],\n",
      "               [225.2308, 239.4572, 101.3018, 109.5961]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 60:\n",
      "boxes = BoundingBoxes([[308.0466, 111.0223, 134.9097, 135.4062],\n",
      "               [164.3059,  90.8829, 133.5847, 133.9604],\n",
      "               [114.8027,  68.2202,  70.3096,  81.0198],\n",
      "               [224.6349,  19.8954, 108.9935,  39.7909],\n",
      "               [198.1587, 323.7325, 137.3248, 137.8069],\n",
      "               [344.4280, 349.0200, 146.0005, 146.3793],\n",
      "               [247.8400, 486.3554, 145.7871, 146.4461],\n",
      "               [111.2418, 474.8054, 130.2470, 130.8327]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 61:\n",
      "boxes = BoundingBoxes([[392.2321, 204.5402, 155.5889, 162.0921]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 62:\n",
      "boxes = BoundingBoxes([[425.8021,   7.5746, 100.5116,   8.2077]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 63:\n",
      "boxes = BoundingBoxes([], size=(0, 4), format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 64:\n",
      "boxes = BoundingBoxes([[254.1889, 294.3132,  86.9711,  84.4809]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 65:\n",
      "boxes = BoundingBoxes([[340.3375,  99.6766, 203.5423, 199.3531],\n",
      "               [492.8880, 589.4943, 116.0058,  68.9927],\n",
      "               [ 21.5126, 346.5860,  43.0252, 137.6059]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 66:\n",
      "boxes = BoundingBoxes([[504.0336,  30.2460, 142.8571,  60.4920],\n",
      "               [298.9916, 452.7234, 149.5798, 110.4877],\n",
      "               [580.0000, 235.8913, 120.0000, 124.2987],\n",
      "               [563.1933, 557.6866, 153.6134, 154.6828],\n",
      "               [107.3950, 323.5909, 210.0840, 164.3504],\n",
      "               [172.1008, 608.5110, 184.8739,  62.9780]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 67:\n",
      "boxes = BoundingBoxes([[553.3669, 207.7668, 173.2663, 163.8437],\n",
      "               [529.8741, 347.7271, 193.3004, 161.8068],\n",
      "               [140.5423, 351.8632, 281.0846, 143.5429]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 68:\n",
      "boxes = BoundingBoxes([[383.1389, 390.9772,  95.9876, 107.3708],\n",
      "               [476.8891, 378.7386,  93.5032, 106.9821],\n",
      "               [421.7012, 604.8976,  98.9980,  70.2047],\n",
      "               [164.3461, 180.7843, 101.8883, 114.1772]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 69:\n",
      "boxes = BoundingBoxes([[335.1120, 428.0533, 139.8495, 167.0351],\n",
      "               [100.4693, 528.8173, 126.8792, 146.7440],\n",
      "               [ 34.7681, 596.0272,  15.8976,  87.9455]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 70:\n",
      "boxes = BoundingBoxes([[ 53.7329, 373.7848, 107.4657, 181.1149],\n",
      "               [ 78.5301, 159.9090, 136.9969, 163.7643],\n",
      "               [195.9530,  41.2319, 109.0763,  76.2028],\n",
      "               [366.3355,  36.2448, 164.5497,  72.4896],\n",
      "               [532.4937,  26.2859, 121.7604,  52.5718],\n",
      "               [604.5895, 120.5985,  59.7128, 156.9437],\n",
      "               [568.7504, 529.3083, 142.4992, 119.5145],\n",
      "               [549.9105, 603.3831, 137.2058,  58.2536],\n",
      "               [289.7888, 614.7713, 150.2641,  50.4573],\n",
      "               [433.3326, 629.3020, 116.7688,  16.8079],\n",
      "               [402.1221, 337.4805, 171.3154, 219.8831]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 71:\n",
      "boxes = BoundingBoxes([[  2.0347, 487.4176,   4.0695,  99.3591],\n",
      "               [119.1628, 582.4749,  93.7133,  98.8826],\n",
      "               [348.3318, 401.2805,  76.8496,  89.0827],\n",
      "               [437.4271, 291.2161,  85.6091,  94.2558],\n",
      "               [331.8718, 222.8003,  86.9493,  92.1967],\n",
      "               [628.0359, 341.1059,  23.9280,  90.5734],\n",
      "               [603.2128, 536.8495,  73.5744,  91.2642],\n",
      "               [555.6418, 433.1750,  84.8794,  83.0111]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 72:\n",
      "boxes = BoundingBoxes([[399.2729, 378.4499,  87.9046,  83.2254],\n",
      "               [117.7539, 251.6351,  96.0108,  90.2248],\n",
      "               [171.6932, 159.4429,  89.5190,  83.2880],\n",
      "               [ 15.2379, 173.6364,  30.4756, 100.6121],\n",
      "               [556.2690, 194.2637,  98.4693,  92.6578]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 73:\n",
      "boxes = BoundingBoxes([[200.9508, 475.4650, 155.5850, 155.5931],\n",
      "               [316.4653, 355.8934, 160.7368, 160.5805],\n",
      "               [126.3937, 301.7748, 163.0037, 162.6554],\n",
      "               [259.7762, 200.8280, 143.2223, 142.8776]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 74:\n",
      "boxes = BoundingBoxes([[247.1185, 631.7894, 150.5461,  16.4212],\n",
      "               [248.7770, 633.4304, 147.2291,  13.1391],\n",
      "               [ 28.7591, 450.2322,  57.5181, 120.4425],\n",
      "               [ 15.7166, 403.5172,  31.4333, 162.2513]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 75:\n",
      "boxes = BoundingBoxes([[453.0822, 389.8510,  65.0685,  69.0293],\n",
      "               [210.6164, 282.1983,  62.3288,  60.8115],\n",
      "               [298.9726, 476.9594,  82.8767,  88.7519],\n",
      "               [340.7534,  82.0955,  67.8082,  89.5737],\n",
      "               [441.4384, 280.1438,  74.6575,  87.9301]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 76:\n",
      "boxes = BoundingBoxes([[210.7651,  16.7588, 112.2355,  33.5177],\n",
      "               [579.8439, 352.5832, 107.3016, 117.9417],\n",
      "               [241.9960, 584.0278,  97.9903,  85.9144],\n",
      "               [441.2525, 102.3350, 102.8539, 114.5350]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 77:\n",
      "boxes = BoundingBoxes([[501.6651, 331.3268, 160.0000, 176.8404],\n",
      "               [437.5472, 540.3857, 224.7065, 199.2285],\n",
      "               [161.7623,  19.4755, 210.0339,  38.9510]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 78:\n",
      "boxes = BoundingBoxes([[577.6515, 285.7033, 116.0959, 348.7150]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 79:\n",
      "boxes = BoundingBoxes([[ 38.3811, 189.1817,  76.7621, 137.5119],\n",
      "               [287.2278,  81.4915, 102.4018, 132.2950],\n",
      "               [413.8446,  60.5222, 159.7190, 121.0444],\n",
      "               [  7.0237, 415.9941,   9.7503, 114.3547]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 80:\n",
      "boxes = BoundingBoxes([[449.4144, 440.0540,  89.8122, 121.7814],\n",
      "               [346.5193, 172.3077, 100.4199, 114.8718],\n",
      "               [239.7348, 422.3482,  76.3757,  95.0067],\n",
      "               [229.4807, 304.0216,  77.0829,  89.8246],\n",
      "               [343.3370, 414.5749,  89.8122, 110.5533],\n",
      "               [346.5193, 291.9298,  94.7624, 107.0985],\n",
      "               [461.4365, 191.3090,  91.2265, 114.8718],\n",
      "               [559.3812, 436.5992,  82.0331, 101.0526],\n",
      "               [557.6133, 319.1363,  79.9116,  94.1430],\n",
      "               [454.0110, 318.7044,  74.9613,  98.4615],\n",
      "               [229.1271, 178.3535,  74.9613,  99.3252],\n",
      "               [558.3204, 190.8772,  75.6685,  91.5520]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 81:\n",
      "boxes = BoundingBoxes([[ 50.5889, 226.4885,  99.8161, 154.9846],\n",
      "               [149.6649,  57.2236, 146.8102, 114.4473],\n",
      "               [ 34.2784,  16.4985,  37.3007,  32.9970],\n",
      "               [357.1118, 334.4925, 153.2849, 160.8173],\n",
      "               [234.5163, 532.3260, 161.9847, 171.9198],\n",
      "               [475.0804, 564.1945, 163.5417, 151.6109],\n",
      "               [584.2993, 400.9353, 111.0738, 149.6571]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 82:\n",
      "boxes = BoundingBoxes([[297.8247, 319.8855, 165.8470, 162.9275]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 83:\n",
      "boxes = BoundingBoxes([[ 19.6151, 466.6906,  39.2302, 124.4508]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 84:\n",
      "boxes = BoundingBoxes([[109.8714,  67.4150, 101.9059, 134.8300]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 85:\n",
      "boxes = BoundingBoxes([[281.5972, 270.6557,  68.4756,  60.6557]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 86:\n",
      "boxes = BoundingBoxes([[ 24.0718, 205.8499,  48.1437,  69.1790],\n",
      "               [532.8422, 541.5623,  64.7931,  70.2375],\n",
      "               [315.5967, 607.5220, 109.0602,  64.9559],\n",
      "               [351.1820, 316.9096, 118.9640, 113.8159],\n",
      "               [169.2790,  34.8744,  78.0454,  69.7487],\n",
      "               [589.6472, 269.3104, 100.7056, 115.0857]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 87:\n",
      "boxes = BoundingBoxes([[596.7917, 268.7363,  86.4166, 127.3632],\n",
      "               [318.1535, 518.6865, 149.5672, 143.2836],\n",
      "               [327.3860, 147.7413, 204.9625, 178.3085]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 88:\n",
      "boxes = BoundingBoxes([[ 83.5931, 530.7826, 167.1861, 118.2118],\n",
      "               [289.8791, 487.0735, 154.0118, 142.1189]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 89:\n",
      "boxes = BoundingBoxes([[307.7208, 345.6192,  93.1871, 104.9247],\n",
      "               [398.7358, 333.6595,  90.7752, 104.5448],\n",
      "               [345.1581, 574.4902,  96.1096, 108.2532],\n",
      "               [ 95.3113, 140.2149,  98.9156, 111.5760],\n",
      "               [619.8710, 129.8244,  40.2579, 106.7799]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 90:\n",
      "boxes = BoundingBoxes([[182.7842, 163.8497, 113.3225, 119.7081],\n",
      "               [ 31.7229, 447.3752,  55.5282, 116.7907],\n",
      "               [356.4883, 529.5986,  99.6079, 105.1205],\n",
      "               [400.2521, 202.1794, 103.1230, 105.0116],\n",
      "               [566.2391, 250.7130, 105.1601, 103.7917]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 91:\n",
      "boxes = BoundingBoxes([[288.0866,  71.7623, 145.5033, 143.5247],\n",
      "               [123.3496,  88.7483, 131.3870, 100.6731],\n",
      "               [ 34.9473, 165.0534,  69.8946, 132.8437],\n",
      "               [  5.4482, 282.3362,  10.8963,  94.7259],\n",
      "               [ 38.0861, 408.8225,  76.1723, 135.9075],\n",
      "               [ 82.7680, 533.8515,  69.1692, 101.5625],\n",
      "               [180.5823, 578.2266, 142.4663, 123.5468],\n",
      "               [409.0444, 434.8156, 140.1664, 191.3383],\n",
      "               [467.9001, 353.5324, 145.6737, 144.9653],\n",
      "               [388.3820, 157.6146, 158.6252, 158.5872],\n",
      "               [441.5916, 260.7536, 114.7375, 120.2119],\n",
      "               [221.8960, 343.0017, 183.0430, 177.2981]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 92:\n",
      "boxes = BoundingBoxes([[ 14.6311, 259.0361,  29.2623, 209.7936],\n",
      "               [ 30.1689, 467.3126,  60.3378, 223.9200],\n",
      "               [547.7204, 194.8601, 184.5592, 230.4980],\n",
      "               [547.4782,  46.3146, 185.0435,  47.9753],\n",
      "               [606.7687, 503.5474,  43.2442, 192.7015]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 93:\n",
      "boxes = BoundingBoxes([[260.3071, 292.9404,  96.1058,  98.8737],\n",
      "               [187.4907, 506.8951, 104.5648, 107.4952],\n",
      "               [271.0280, 551.5215,  96.9952,  99.6122],\n",
      "               [453.1845, 360.9809, 107.3157, 110.3379]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 94:\n",
      "boxes = BoundingBoxes([], size=(0, 4), format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 95:\n",
      "boxes = BoundingBoxes([[463.5564, 415.8126,  53.4868,  83.3406],\n",
      "               [537.5403, 406.6169,  87.0363,  98.4955],\n",
      "               [497.7438, 542.9536,  72.7082,  59.3857],\n",
      "               [389.1901, 575.3822,  87.4952,  98.7905],\n",
      "               [361.4532, 218.0096,  51.1924,  81.0811]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 96:\n",
      "boxes = BoundingBoxes([[552.0053, 617.5824, 134.2804,  13.9752],\n",
      "               [543.4550, 601.3469, 193.0900,  53.6228]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 97:\n",
      "boxes = BoundingBoxes([[399.7637,  50.4954, 106.6047, 100.9908],\n",
      "               [370.0996, 604.2026,  93.0742,  71.5948],\n",
      "               [180.8396, 164.3658,  97.6938, 105.4773]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 98:\n",
      "boxes = BoundingBoxes([[583.1917, 420.5351,  74.6417,  79.9604],\n",
      "               [528.2224, 157.5239,  68.6180,  92.3974],\n",
      "               [500.7247,  50.1700,  96.3681, 100.3400],\n",
      "               [310.7657, 143.9541, 137.2359,  88.5215],\n",
      "               [346.3347,   9.1400,  94.3499,  18.2801],\n",
      "               [382.4509, 368.7259,  90.0756, 116.8772],\n",
      "               [472.2301, 533.1817,  62.5861, 181.0608]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "\n",
      "Image 99:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_dataset)):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_dataset[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ora mi viene un dubbio, che tipo di immagini ci sono nel nostro dataset di validation?\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Display image 51\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Train dataset \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Trial/DataAugmentation.py:69\u001b[0m, in \u001b[0;36mDatasetAugmentation.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m img_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[idx]) \n\u001b[1;32m     68\u001b[0m label_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx])\n\u001b[0;32m---> 69\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImageReadMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m _, H, W \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m# otteniamo larghezza e altezza dell'immagine\u001b[39;00m\n\u001b[1;32m     72\u001b[0m boxes_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/iapr_project/lib/python3.9/site-packages/torchvision/io/image.py:337\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode, apply_exif_orientation)\u001b[0m\n\u001b[1;32m    335\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m    336\u001b[0m data \u001b[38;5;241m=\u001b[39m read_file(path)\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_exif_orientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_exif_orientation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/iapr_project/lib/python3.9/site-packages/torchvision/io/image.py:324\u001b[0m, in \u001b[0;36mdecode_image\u001b[0;34m(input, mode, apply_exif_orientation)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    323\u001b[0m     mode \u001b[38;5;241m=\u001b[39m ImageReadMode[mode\u001b[38;5;241m.\u001b[39mupper()]\n\u001b[0;32m--> 324\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_exif_orientation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniforge3/envs/iapr_project/lib/python3.9/site-packages/torch/_ops.py:1123\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Analyse some statistics of the dataset \n",
    "# 1. Number of images\n",
    "num_images = len(val_dataset)\n",
    "print(f\"Number of images in the validation dataset: {type(num_images)}\")\n",
    "print(\"Dimnension of the images in the validation dataset:\", type(val_dataset[0][0])) # RGB images of 640x640 --> [3, 640, 640]\n",
    "# se faccio  type(val_dataset[0][0]) ottengo class 'torchvision.tv_tensors._image.Image\n",
    "# 2. Number of classes\n",
    "print(f\"Number of classes in the validation dataset: {val_dataset[0][1].data}\") # Se gli passo val_dataset[0][1] ottengo questo tipo: \n",
    "# BoundingBoxes([[362.1333, 360.4000,  58.6667,  87.2000]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640)), mentre se gli passo questo: \n",
    "# val_dataset[0][1].data ottengo tensor([[362.1333, 360.4000,  58.6667,  87.2000]])\n",
    "\n",
    "# 3. Number of bounding boxes\n",
    "print(f\"Number of bounding boxes in the validation dataset: {val_dataset[0][2]}\") # 4 bounding boxes in the image\n",
    "\n",
    "\n",
    "# Print all the bounding boxes in the validation set \n",
    "# for i in range(len(val_dataset)):\n",
    "#     print(f\"Image {i}:\")\n",
    "#     print(f\"boxes = {val_dataset[i][1]}\\n\")\n",
    "\n",
    "\n",
    "# Il codice si spacca all'immagine 51\n",
    "# print the bounding boxes from image 51, 63, 94, 101, 102, 105\n",
    "for i in range(1, len(val_dataset)):\n",
    "    print(f\"Image {i}:\")\n",
    "    print(f\"boxes = {val_dataset[i][1]}\\n\")\n",
    "\n",
    "\n",
    "# ora mi viene un dubbio, che tipo di immagini ci sono nel nostro dataset di validation?\n",
    "\n",
    "# Display image 51\n",
    "\n",
    "# Read all the images in \"augmented_data/val/images\" and store them in a vector, then print the image 51\n",
    "\n",
    "\n",
    "\n",
    "# Train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51st image filename: Choco_000052.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Path to your images folder\n",
    "image_folder = '/Users/emanuelerimoldi/Desktop/Trial/augmented_data/val/images'\n",
    "\n",
    "# List of image filenames sorted alphabetically\n",
    "image_files = sorted([file for file in os.listdir(image_folder) if file.lower().endswith(('png', 'jpg', 'jpeg'))])\n",
    "\n",
    "# Load images into a list\n",
    "images = [Image.open(os.path.join(image_folder, file)) for file in image_files]\n",
    "\n",
    "# Check if there are at least 51 images\n",
    "if len(images) >= 52:\n",
    "    print(f\"51st image filename: {image_files[51]}\")\n",
    "    images[50].show()  # this will display the image\n",
    "else:\n",
    "    print(\"There are fewer than 51 images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, boxes_list, labels_list = zip(*batch) # Unzip the batch, * is used to unpack the list of tuples\n",
    "    images = torch.stack(images, dim=0) \n",
    "    targets = []\n",
    "    for batch_idx, (bbs, labels) in enumerate(zip(boxes_list, labels_list)):\n",
    "        # bbs.data is (num_objs, 4) in CXCYWH absolute pixels\n",
    "        coords = bbs.data  # torch.Tensor\n",
    "        H, W = bbs.canvas_size\n",
    "        # normalize [cx,cy,w,h]\n",
    "        coords = coords / torch.tensor([W, H, W, H], dtype=torch.float32, device=coords.device)\n",
    "        cls   = labels.to(torch.float32).view(-1,1)\n",
    "        idxs  = torch.full((coords.size(0),1), batch_idx, dtype=torch.float32, device=coords.device)\n",
    "        targets.append(torch.cat([idxs, cls, coords], dim=1))\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    return images, {\n",
    "        \"batch_idx\": targets[:,0].long(),\n",
    "        \"cls\":       targets[:,1],\n",
    "        \"bboxes\":    targets[:,2:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading datasets...\n",
      "Train dataset size: 556\n",
      "Values per training sample: 3\n",
      "Sample bounding boxes: BoundingBoxes([[204.9067, 264.6832,  48.2133,  64.7264],\n",
      "               [382.2400, 163.6448,  49.4581,  59.4496],\n",
      "               [528.0181, 242.9744,  47.3248,  58.1088],\n",
      "               [487.0048, 384.3392,  38.5419,  76.8400],\n",
      "               [364.7648, 338.7920,  45.7952,  65.7456],\n",
      "               [356.6752, 537.5936,  36.3733,  74.5472],\n",
      "               [194.6134, 475.2176,  50.3819,  51.6608]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "Sample labels: tensor([5, 6, 5, 4, 6, 4, 4])\n",
      "Validation dataset size: 147\n",
      "Values per validation sample: 3\n",
      "Sample bounding boxes: BoundingBoxes([[291.2245, 205.3696,  56.9845,  86.9888],\n",
      "               [284.6859, 335.8320,  59.1627,  89.3328],\n",
      "               [377.9979, 273.2032,  60.3328,  89.9744],\n",
      "               [358.2325, 401.3488,  53.0795,  78.9296]], format=BoundingBoxFormat.CXCYWH, canvas_size=(640, 640))\n",
      "Sample labels: tensor([ 7,  3, 11,  1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters and settings\n",
    "MODEL_PATH = \"yolo12.yaml\"\n",
    "OUT_DIR = \"output_dir\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 6\n",
    "N_EPOCHS = 30\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "resize_transform = v2.Compose([\n",
    "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    v2.SanitizeBoundingBoxes(),\n",
    "    v2.ToImage(),\n",
    "])\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "train_dataset = DatasetAugmentation(\n",
    "    training_path=\"augmented_data/train\",\n",
    "    split_images=False,\n",
    "    perform_transformations=True\n",
    ")\n",
    "train_dataset.transforms = resize_transform\n",
    "\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Values per training sample: {len(train_dataset[10])}\")\n",
    "#Print the 2nd and 3rd elements of the first sample\n",
    "print(f\"Sample bounding boxes: {train_dataset[10][1]}\")\n",
    "print(f\"Sample labels: {train_dataset[10][2]}\")\n",
    "\n",
    "\n",
    "val_dataset = DatasetAugmentation(\n",
    "    training_path=\"augmented_data/val\",\n",
    "    split_images=False,\n",
    "    perform_transformations=True\n",
    ")\n",
    "val_dataset.transforms = resize_transform\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Values per validation sample: {len(val_dataset[10])}\")\n",
    "# Print the 2nd and 3rd elements of the first sample\n",
    "print(f\"Sample bounding boxes: {val_dataset[10][1]}\")\n",
    "print(f\"Sample labels: {val_dataset[10][2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating dataloaders...\")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # use 0 for notebooks; increase if your environment supports it\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 93\n",
      "\n",
      "Batch 0:\n",
      "  Element 0 - Tensor shape: torch.Size([6, 3, 640, 640]), dtype: torch.uint8\n",
      "  Element 1 - Dict with keys: ['batch_idx', 'cls', 'bboxes']\n",
      "    Key 'batch_idx': shape torch.Size([40]), dtype torch.int64\n",
      "    Key 'cls': shape torch.Size([40]), dtype torch.float32\n",
      "    Key 'bboxes': shape torch.Size([40, 4]), dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "\n",
    "# Prendi un batch di esempio\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    print(f\"\\nBatch {batch_idx}:\")\n",
    "    \n",
    "    # Se il batch  una tupla (es. immagini e target)\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        for i, elem in enumerate(batch):\n",
    "            # Se l'elemento  un tensore, stampa forma e tipo\n",
    "            if isinstance(elem, torch.Tensor):\n",
    "                print(f\"  Element {i} - Tensor shape: {elem.shape}, dtype: {elem.dtype}\")\n",
    "            # Se  un dizionario o altro, stampa tipo e dimensioni se possibile\n",
    "            elif isinstance(elem, dict):\n",
    "                print(f\"  Element {i} - Dict with keys: {list(elem.keys())}\")\n",
    "                for k, v in elem.items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        print(f\"    Key '{k}': shape {v.shape}, dtype {v.dtype}\")\n",
    "            else:\n",
    "                print(f\"  Element {i} - Type: {type(elem)}\")\n",
    "    else:\n",
    "        # Se batch non  tupla/list, prova a stampare tipo e shape\n",
    "        if isinstance(batch, torch.Tensor):\n",
    "            print(f\"Batch is a tensor with shape {batch.shape}, dtype {batch.dtype}\")\n",
    "        else:\n",
    "            print(f\"Batch type: {type(batch)}\")\n",
    "\n",
    "    # Dopo il primo batch esci dal ciclo (se vuoi vedere solo il primo)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "Total number of parameters in the model: 2570583\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Initializing model...\")\n",
    "model_yolo = YOLO(MODEL_PATH)\n",
    "model = model_yolo.model\n",
    "num_params_all = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in the model: {num_params_all}\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C3k2(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C3k2(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): A2C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Sequential(\n",
      "          (0): ABlock(\n",
      "            (attn): AAttn(\n",
      "              (qkv): Conv(\n",
      "                (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (proj): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (pe): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Sequential(\n",
      "              (0): Conv(\n",
      "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (1): Conv(\n",
      "                (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ABlock(\n",
      "            (attn): AAttn(\n",
      "              (qkv): Conv(\n",
      "                (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (proj): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (pe): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Sequential(\n",
      "              (0): Conv(\n",
      "                (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (1): Conv(\n",
      "                (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): A2C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Sequential(\n",
      "          (0): ABlock(\n",
      "            (attn): AAttn(\n",
      "              (qkv): Conv(\n",
      "                (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (proj): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (pe): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Sequential(\n",
      "              (0): Conv(\n",
      "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (1): Conv(\n",
      "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ABlock(\n",
      "            (attn): AAttn(\n",
      "              (qkv): Conv(\n",
      "                (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (proj): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "              (pe): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "            (mlp): Sequential(\n",
      "              (0): Conv(\n",
      "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (1): Conv(\n",
      "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): Identity()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (10): Concat()\n",
      "    (11): A2C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): C3k(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (13): Concat()\n",
      "    (14): A2C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): C3k(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (16): Concat()\n",
      "    (17): A2C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): C3k(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (19): Concat()\n",
      "    (20): C3k2(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): C3k(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): Detect(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): DWConv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): DWConv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): DWConv(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): DWConv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Sequential(\n",
      "            (0): DWConv(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): DWConv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "              (act): SiLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing optimizer and scheduler...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Initializing optimizer and scheduler...\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "total_steps = N_EPOCHS * len(train_loader)\n",
    "warmup_steps = int(0.3 * total_steps)\n",
    "sched1 = LinearLR(optimizer, start_factor=1e-3, total_iters=warmup_steps)\n",
    "sched2 = CosineAnnealingLR(optimizer, T_max=total_steps - warmup_steps, eta_min=1e-6)\n",
    "scheduler = SequentialLR(optimizer, [sched1, sched2], [warmup_steps])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedDict(dict):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss = v8DetectionLoss(model)\n",
    "compute_loss.hyp = FixedDict(compute_loss.hyp)\n",
    "\n",
    "\n",
    "loss_history_train = []\n",
    "loss_history_val = []\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using device: cpu ...\n",
      "Epoch 1/30\n",
      "Type of targets['batch_idx']: <class 'torch.Tensor'>\n",
      "Shape of targets['batch_idx']: torch.Size([23]), dtype: torch.int64\n",
      "Type of targets['cls']: <class 'torch.Tensor'>\n",
      "Shape of targets['cls']: torch.Size([23]), dtype: torch.float32\n",
      "Type of targets['bboxes']: <class 'torch.Tensor'>\n",
      "Shape of targets['bboxes']: torch.Size([23, 4]), dtype: torch.float32\n",
      "Batch 0 loss before backward: 7.445131778717041\n",
      "Type of targets['batch_idx']: <class 'torch.Tensor'>\n",
      "Shape of targets['batch_idx']: torch.Size([36]), dtype: torch.int64\n",
      "Type of targets['cls']: <class 'torch.Tensor'>\n",
      "Shape of targets['cls']: torch.Size([36]), dtype: torch.float32\n",
      "Type of targets['bboxes']: <class 'torch.Tensor'>\n",
      "Shape of targets['bboxes']: torch.Size([36, 4]), dtype: torch.float32\n",
      "Batch 1 loss before backward: 5.38627290725708\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss before backward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/iapr_project/lib/python3.9/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/iapr_project/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/iapr_project/lib/python3.9/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"Starting training using device: {device} ...\")\n",
    "for epoch in range(1, 3):\n",
    "    print(f\"Epoch {epoch}/{N_EPOCHS}\")\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device, non_blocking=True).float() / 255.0\n",
    "        targets = {k: v.to(device, non_blocking=True) for k, v in targets.items()}\n",
    "\n",
    "        # Stampa il tipo e la forma di ciascun target\n",
    "        #for k, v in targets.items():\n",
    "           # print(f\"Type of targets['{k}']: {type(v)}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "\n",
    "        loss, _ = compute_loss(preds, targets)\n",
    "        loss = loss.sum() / imgs.shape[0]\n",
    "\n",
    "        print(f\"Batch {batch_idx} loss before backward: {loss.item()}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Valutazione su validation set solo se non  stato fatto break nel training\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (imgs, targets) in enumerate(val_loader):\n",
    "            imgs = imgs.to(device, non_blocking=True).float() / 255.0\n",
    "            targets = {k: v.to(device, non_blocking=True) for k, v in targets.items()}\n",
    "\n",
    "            preds = model(imgs)\n",
    "\n",
    "            loss, _ = compute_loss(preds, targets)\n",
    "            loss = loss.sum() / imgs.shape[0]\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    loss_history_train.append(avg_train_loss)\n",
    "    loss_history_val.append(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = epoch\n",
    "        best_model_state = model.state_dict()\n",
    "        print(f\"New best model at epoch {epoch} with val loss {best_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saving best model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete. Saving best model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mbest_model_state\u001b[49m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_history_train,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_history_val,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_epoch,\n\u001b[1;32m      8\u001b[0m }, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_data.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model_state' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training complete. Saving best model...\")\n",
    "torch.save(best_model_state, os.path.join(OUT_DIR, \"best.pt\"))\n",
    "torch.save(model.state_dict(), os.path.join(OUT_DIR, \"last.pt\"))\n",
    "torch.save({\n",
    "    \"train_loss\": loss_history_train,\n",
    "    \"val_loss\": loss_history_val,\n",
    "    \"best_epoch\": best_epoch,\n",
    "}, os.path.join(OUT_DIR, \"plot_data.pt\"))\n",
    "\n",
    "print(\"Plotting loss curves...\")\n",
    "epochs = range(1, N_EPOCHS + 1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, loss_history_train, label=\"Train Loss\")\n",
    "plt.plot(epochs, loss_history_val, label=\"Val Loss\")\n",
    "plt.axvline(best_epoch, linestyle=\"--\", color=\"red\", label=f\"Best Epoch: {best_epoch}\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iapr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
